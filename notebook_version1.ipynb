{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9626e920",
   "metadata": {
    "_cell_guid": "1b5942cf-d5b4-4fc4-b129-03da60154f99",
    "_uuid": "501667a7-ba6d-483d-8ff6-8cb1bf834cd9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-11T01:33:54.003847Z",
     "iopub.status.busy": "2025-03-11T01:33:54.003517Z",
     "iopub.status.idle": "2025-03-11T01:33:54.757325Z",
     "shell.execute_reply": "2025-03-11T01:33:54.756457Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.758624,
     "end_time": "2025-03-11T01:33:54.758972",
     "exception": false,
     "start_time": "2025-03-11T01:33:54.000348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2bbf93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T01:33:54.763973Z",
     "iopub.status.busy": "2025-03-11T01:33:54.763656Z",
     "iopub.status.idle": "2025-03-11T01:33:58.024178Z",
     "shell.execute_reply": "2025-03-11T01:33:58.023476Z"
    },
    "papermill": {
     "duration": 3.264666,
     "end_time": "2025-03-11T01:33:58.025890",
     "exception": false,
     "start_time": "2025-03-11T01:33:54.761224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNetdl():\n",
    "    return ResNet(BasicBlock, [1, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35661912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T01:33:58.030633Z",
     "iopub.status.busy": "2025-03-11T01:33:58.030256Z",
     "iopub.status.idle": "2025-03-11T01:34:14.275150Z",
     "shell.execute_reply": "2025-03-11T01:34:14.274449Z"
    },
    "papermill": {
     "duration": 16.249016,
     "end_time": "2025-03-11T01:34:14.276924",
     "exception": false,
     "start_time": "2025-03-11T01:33:58.027908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# auto. choose CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Function to load CIFAR-10 dataset\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Specify the directory containing CIFAR-10 batches\n",
    "cifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n",
    "\n",
    "# Load metadata (labels)\n",
    "meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n",
    "label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n",
    "\n",
    "# Load training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']\n",
    "\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n",
    "])\n",
    "\n",
    "# Convert to TensorDataset and apply transformations\n",
    "class CustomCIFAR10Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Load test dataset\n",
    "cifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "test_batch = load_cifar_batch(cifar_test_path)\n",
    "test_images = test_batch[b'data'].astype(np.float32) / 255.0\n",
    "test_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "\n",
    "# Convert test dataset to Tensor\n",
    "test_dataset = [(transform(img)) for img in test_images]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_loader, val_loader, epochs=50):\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n",
    "    # scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa68ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T01:34:14.282327Z",
     "iopub.status.busy": "2025-03-11T01:34:14.281968Z",
     "iopub.status.idle": "2025-03-11T02:19:20.935871Z",
     "shell.execute_reply": "2025-03-11T02:19:20.934787Z"
    },
    "papermill": {
     "duration": 2706.65796,
     "end_time": "2025-03-11T02:19:20.937286",
     "exception": false,
     "start_time": "2025-03-11T01:34:14.279326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "            Conv2d-2           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "            Conv2d-6           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "            Conv2d-9           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-13           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "           Conv2d-19          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-23          [-1, 128, 16, 16]               0\n",
      "           Conv2d-24          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "           Conv2d-26            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-27            [-1, 256, 8, 8]             512\n",
      "           Conv2d-28          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-30          [-1, 128, 16, 16]               0\n",
      "           Conv2d-31            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-32            [-1, 256, 8, 8]             512\n",
      "           Conv2d-33            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "           Conv2d-35            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
      "           Conv2d-40            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-41            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-42            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-43            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-44            [-1, 256, 8, 8]               0\n",
      "           Conv2d-45            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-47            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-48            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-49            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-50            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-51            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-53            [-1, 512, 4, 4]         131,072\n",
      "       BasicBlock-54            [-1, 512, 4, 4]               0\n",
      "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-56            [-1, 512, 4, 4]               0\n",
      "           Linear-57                   [-1, 10]           5,130\n",
      "           Linear-58                   [-1, 10]           5,130\n",
      "           ResNet-59                   [-1, 10]               0\n",
      "           ResNet-60                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 9,806,484\n",
      "Trainable params: 9,806,484\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.13\n",
      "Params size (MB): 37.41\n",
      "Estimated Total Size (MB): 50.55\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, Loss: 1.722101896323941, Validation Accuracy: 42.48%\n",
      "Epoch 2, Loss: 1.2833570748228917, Validation Accuracy: 51.72%\n",
      "Epoch 3, Loss: 1.0886217928068205, Validation Accuracy: 57.66%\n",
      "Epoch 4, Loss: 0.9334626494144852, Validation Accuracy: 68.78%\n",
      "Epoch 5, Loss: 0.8139814959669655, Validation Accuracy: 69.56%\n",
      "Epoch 6, Loss: 0.7508645552125844, Validation Accuracy: 72.64%\n",
      "Epoch 7, Loss: 0.6898827647620981, Validation Accuracy: 72.96%\n",
      "Epoch 8, Loss: 0.6496255160732702, Validation Accuracy: 66.86%\n",
      "Epoch 9, Loss: 0.6236369467594407, Validation Accuracy: 75.94%\n",
      "Epoch 10, Loss: 0.6037283555011858, Validation Accuracy: 74.76%\n",
      "Epoch 11, Loss: 0.5857146968218413, Validation Accuracy: 76.24%\n",
      "Epoch 12, Loss: 0.5654181704263795, Validation Accuracy: 74.44%\n",
      "Epoch 13, Loss: 0.5580270469019358, Validation Accuracy: 73.9%\n",
      "Epoch 14, Loss: 0.5428736493499442, Validation Accuracy: 79.08%\n",
      "Epoch 15, Loss: 0.5320054967464372, Validation Accuracy: 79.66%\n",
      "Epoch 16, Loss: 0.5302281731062315, Validation Accuracy: 78.38%\n",
      "Epoch 17, Loss: 0.523661712015217, Validation Accuracy: 76.74%\n",
      "Epoch 18, Loss: 0.5156951973384077, Validation Accuracy: 79.56%\n",
      "Epoch 19, Loss: 0.4997072438286109, Validation Accuracy: 71.56%\n",
      "Epoch 20, Loss: 0.5022845368155024, Validation Accuracy: 78.92%\n",
      "Epoch 21, Loss: 0.4910935758697716, Validation Accuracy: 78.3%\n",
      "Epoch 22, Loss: 0.48772634989158675, Validation Accuracy: 78.28%\n",
      "Epoch 23, Loss: 0.48404088599438017, Validation Accuracy: 80.7%\n",
      "Epoch 24, Loss: 0.4812843983315609, Validation Accuracy: 74.08%\n",
      "Epoch 25, Loss: 0.47415638325566595, Validation Accuracy: 75.02%\n",
      "Epoch 26, Loss: 0.476795597340573, Validation Accuracy: 78.1%\n",
      "Epoch 27, Loss: 0.47316870533607225, Validation Accuracy: 80.22%\n",
      "Epoch 28, Loss: 0.46349775342440064, Validation Accuracy: 79.12%\n",
      "Epoch 29, Loss: 0.4676003379069946, Validation Accuracy: 76.16%\n",
      "Epoch 30, Loss: 0.4621797826733779, Validation Accuracy: 72.2%\n",
      "Epoch 31, Loss: 0.45987824092365126, Validation Accuracy: 73.28%\n",
      "Epoch 32, Loss: 0.460534609938887, Validation Accuracy: 75.48%\n",
      "Epoch 33, Loss: 0.45349182383241976, Validation Accuracy: 80.52%\n",
      "Epoch 34, Loss: 0.45128970076753333, Validation Accuracy: 80.6%\n",
      "Epoch 35, Loss: 0.4464772725901143, Validation Accuracy: 76.54%\n",
      "Epoch 36, Loss: 0.443654067306356, Validation Accuracy: 77.98%\n",
      "Epoch 37, Loss: 0.4441855073991147, Validation Accuracy: 75.9%\n",
      "Epoch 38, Loss: 0.43765457660298457, Validation Accuracy: 78.78%\n",
      "Epoch 39, Loss: 0.44396568640050565, Validation Accuracy: 79.92%\n",
      "Epoch 40, Loss: 0.43686122112822806, Validation Accuracy: 80.14%\n",
      "Epoch 41, Loss: 0.4442048000002449, Validation Accuracy: 79.9%\n",
      "Epoch 42, Loss: 0.4319668274203485, Validation Accuracy: 76.7%\n",
      "Epoch 43, Loss: 0.4326575379818678, Validation Accuracy: 83.3%\n",
      "Epoch 44, Loss: 0.4295204810120843, Validation Accuracy: 77.14%\n",
      "Epoch 45, Loss: 0.42931976038115943, Validation Accuracy: 81.28%\n",
      "Epoch 46, Loss: 0.42690471170300787, Validation Accuracy: 81.32%\n",
      "Epoch 47, Loss: 0.4306531300852922, Validation Accuracy: 79.8%\n",
      "Epoch 48, Loss: 0.42678705674850126, Validation Accuracy: 78.76%\n",
      "Epoch 49, Loss: 0.41903711144219746, Validation Accuracy: 78.72%\n",
      "Epoch 50, Loss: 0.42288993955166504, Validation Accuracy: 78.78%\n",
      "Epoch 51, Loss: 0.41312677785754204, Validation Accuracy: 78.28%\n",
      "Epoch 52, Loss: 0.4166254432533275, Validation Accuracy: 76.36%\n",
      "Epoch 53, Loss: 0.41381088496101176, Validation Accuracy: 79.68%\n",
      "Epoch 54, Loss: 0.41153729266741057, Validation Accuracy: 74.46%\n",
      "Epoch 55, Loss: 0.4103061879815703, Validation Accuracy: 83.14%\n",
      "Epoch 56, Loss: 0.41400933832946146, Validation Accuracy: 77.48%\n",
      "Epoch 57, Loss: 0.4003729470158843, Validation Accuracy: 81.36%\n",
      "Epoch 58, Loss: 0.4028131786141206, Validation Accuracy: 80.72%\n",
      "Epoch 59, Loss: 0.39964355469088664, Validation Accuracy: 79.9%\n",
      "Epoch 60, Loss: 0.40114192939786747, Validation Accuracy: 81.24%\n",
      "Epoch 61, Loss: 0.39630537310784514, Validation Accuracy: 82.06%\n",
      "Epoch 62, Loss: 0.39219891821796243, Validation Accuracy: 79.34%\n",
      "Epoch 63, Loss: 0.39571867332878435, Validation Accuracy: 81.14%\n",
      "Epoch 64, Loss: 0.3903012759136883, Validation Accuracy: 80.1%\n",
      "Epoch 65, Loss: 0.3864163360981779, Validation Accuracy: 79.24%\n",
      "Epoch 66, Loss: 0.3832566793584688, Validation Accuracy: 76.2%\n",
      "Epoch 67, Loss: 0.3887681192718446, Validation Accuracy: 81.92%\n",
      "Epoch 68, Loss: 0.38002756906842644, Validation Accuracy: 82.82%\n",
      "Epoch 69, Loss: 0.38507069926708937, Validation Accuracy: 80.96%\n",
      "Epoch 70, Loss: 0.38400243946605106, Validation Accuracy: 79.32%\n",
      "Epoch 71, Loss: 0.3764476516622711, Validation Accuracy: 82.82%\n",
      "Epoch 72, Loss: 0.37893995820459997, Validation Accuracy: 82.26%\n",
      "Epoch 73, Loss: 0.3715143530121581, Validation Accuracy: 79.62%\n",
      "Epoch 74, Loss: 0.36873824924061244, Validation Accuracy: 83.62%\n",
      "Epoch 75, Loss: 0.36618952169506386, Validation Accuracy: 77.14%\n",
      "Epoch 76, Loss: 0.3676643240773542, Validation Accuracy: 82.32%\n",
      "Epoch 77, Loss: 0.35773450195450673, Validation Accuracy: 82.3%\n",
      "Epoch 78, Loss: 0.361972147217867, Validation Accuracy: 80.92%\n",
      "Epoch 79, Loss: 0.3583258425139568, Validation Accuracy: 83.36%\n",
      "Epoch 80, Loss: 0.3622411064888266, Validation Accuracy: 81.94%\n",
      "Epoch 81, Loss: 0.35238030193034897, Validation Accuracy: 82.04%\n",
      "Epoch 82, Loss: 0.3538304866630245, Validation Accuracy: 81.88%\n",
      "Epoch 83, Loss: 0.3445167870853435, Validation Accuracy: 81.44%\n",
      "Epoch 84, Loss: 0.34841975781389256, Validation Accuracy: 84.28%\n",
      "Epoch 85, Loss: 0.3478204649449749, Validation Accuracy: 83.86%\n",
      "Epoch 86, Loss: 0.34438750897110865, Validation Accuracy: 84.92%\n",
      "Epoch 87, Loss: 0.34142798494378274, Validation Accuracy: 84.74%\n",
      "Epoch 88, Loss: 0.34212263944474136, Validation Accuracy: 81.96%\n",
      "Epoch 89, Loss: 0.3348745402287353, Validation Accuracy: 81.2%\n",
      "Epoch 90, Loss: 0.33336748724633997, Validation Accuracy: 84.98%\n",
      "Epoch 91, Loss: 0.3318320318463851, Validation Accuracy: 79.08%\n",
      "Epoch 92, Loss: 0.32858616922220046, Validation Accuracy: 84.4%\n",
      "Epoch 93, Loss: 0.33302395981313154, Validation Accuracy: 82.28%\n",
      "Epoch 94, Loss: 0.3214168945242735, Validation Accuracy: 83.7%\n",
      "Epoch 95, Loss: 0.3209484845230525, Validation Accuracy: 83.22%\n",
      "Submission5 file saved.\n"
     ]
    }
   ],
   "source": [
    "# put models to devices (CPU/GPU)\n",
    "model = ResNetdl()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Print the number of parameters\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 32, 32))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=95) #change epoch\n",
    "\n",
    "# Generate submission file\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device) \n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('/kaggle/working/submission5.csv', index=False)\n",
    "print(\"Submission5 file saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2731.505911,
   "end_time": "2025-03-11T02:19:22.869538",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T01:33:51.363627",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

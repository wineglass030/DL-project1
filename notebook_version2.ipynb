{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f1fc4e",
   "metadata": {
    "_cell_guid": "1b5942cf-d5b4-4fc4-b129-03da60154f99",
    "_uuid": "501667a7-ba6d-483d-8ff6-8cb1bf834cd9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-11T02:28:01.945225Z",
     "iopub.status.busy": "2025-03-11T02:28:01.944867Z",
     "iopub.status.idle": "2025-03-11T02:28:03.433859Z",
     "shell.execute_reply": "2025-03-11T02:28:03.432644Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.494568,
     "end_time": "2025-03-11T02:28:03.435707",
     "exception": false,
     "start_time": "2025-03-11T02:28:01.941139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05341c2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T02:28:03.441639Z",
     "iopub.status.busy": "2025-03-11T02:28:03.441196Z",
     "iopub.status.idle": "2025-03-11T02:28:10.322807Z",
     "shell.execute_reply": "2025-03-11T02:28:10.321477Z"
    },
    "papermill": {
     "duration": 6.886456,
     "end_time": "2025-03-11T02:28:10.324779",
     "exception": false,
     "start_time": "2025-03-11T02:28:03.438323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNetdl():\n",
    "    return ResNet(BasicBlock, [1, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8711ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T02:28:10.330823Z",
     "iopub.status.busy": "2025-03-11T02:28:10.330284Z",
     "iopub.status.idle": "2025-03-11T02:28:30.242230Z",
     "shell.execute_reply": "2025-03-11T02:28:30.241076Z"
    },
    "papermill": {
     "duration": 19.916959,
     "end_time": "2025-03-11T02:28:30.244235",
     "exception": false,
     "start_time": "2025-03-11T02:28:10.327276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# auto. choose CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Function to load CIFAR-10 dataset\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Specify the directory containing CIFAR-10 batches\n",
    "cifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n",
    "\n",
    "# Load metadata (labels)\n",
    "meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n",
    "label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n",
    "\n",
    "# Load training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']\n",
    "\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n",
    "])\n",
    "\n",
    "# Convert to TensorDataset and apply transformations\n",
    "class CustomCIFAR10Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Load test dataset\n",
    "cifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "test_batch = load_cifar_batch(cifar_test_path)\n",
    "test_images = test_batch[b'data'].astype(np.float32) / 255.0\n",
    "test_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "\n",
    "# Convert test dataset to Tensor\n",
    "test_dataset = [(transform(img)) for img in test_images]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_loader, val_loader, epochs=50):\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n",
    "    # scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ada696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T02:28:30.249825Z",
     "iopub.status.busy": "2025-03-11T02:28:30.249388Z",
     "iopub.status.idle": "2025-03-11T04:01:04.636589Z",
     "shell.execute_reply": "2025-03-11T04:01:04.635180Z"
    },
    "papermill": {
     "duration": 5554.391738,
     "end_time": "2025-03-11T04:01:04.638396",
     "exception": false,
     "start_time": "2025-03-11T02:28:30.246658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,728\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
      "           Conv2d-12          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-14          [-1, 128, 16, 16]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "           Conv2d-17            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-18            [-1, 256, 8, 8]             512\n",
      "           Conv2d-19            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-20            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-21            [-1, 256, 8, 8]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-24            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-25            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-26            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-28            [-1, 512, 4, 4]               0\n",
      "           Linear-29                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,903,242\n",
      "Trainable params: 4,903,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.56\n",
      "Params size (MB): 18.70\n",
      "Estimated Total Size (MB): 25.28\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, Loss: 1.6437321190129628, Validation Accuracy: 48.06%\n",
      "Epoch 2, Loss: 1.2394239971922203, Validation Accuracy: 56.0%\n",
      "Epoch 3, Loss: 1.039101668548855, Validation Accuracy: 64.38%\n",
      "Epoch 4, Loss: 0.9188748235729608, Validation Accuracy: 68.7%\n",
      "Epoch 5, Loss: 0.811548974364996, Validation Accuracy: 68.78%\n",
      "Epoch 6, Loss: 0.7358456897464666, Validation Accuracy: 71.46%\n",
      "Epoch 7, Loss: 0.6885109625926072, Validation Accuracy: 73.32%\n",
      "Epoch 8, Loss: 0.6556265351616524, Validation Accuracy: 71.46%\n",
      "Epoch 9, Loss: 0.6269562660970471, Validation Accuracy: 71.1%\n",
      "Epoch 10, Loss: 0.5960068927908485, Validation Accuracy: 76.2%\n",
      "Epoch 11, Loss: 0.5868952537632801, Validation Accuracy: 74.64%\n",
      "Epoch 12, Loss: 0.5663351132957772, Validation Accuracy: 77.84%\n",
      "Epoch 13, Loss: 0.5597317977385088, Validation Accuracy: 69.46%\n",
      "Epoch 14, Loss: 0.5398721261457964, Validation Accuracy: 75.74%\n",
      "Epoch 15, Loss: 0.5316774510693821, Validation Accuracy: 79.2%\n",
      "Epoch 16, Loss: 0.5219167177142068, Validation Accuracy: 78.42%\n",
      "Epoch 17, Loss: 0.513871946033429, Validation Accuracy: 80.42%\n",
      "Epoch 18, Loss: 0.5043912345374172, Validation Accuracy: 75.36%\n",
      "Epoch 19, Loss: 0.5011310537599705, Validation Accuracy: 74.6%\n",
      "Epoch 20, Loss: 0.4985551175407388, Validation Accuracy: 77.18%\n",
      "Epoch 21, Loss: 0.4919063347307118, Validation Accuracy: 79.86%\n",
      "Epoch 22, Loss: 0.4842856263911182, Validation Accuracy: 75.54%\n",
      "Epoch 23, Loss: 0.4768044300885363, Validation Accuracy: 73.54%\n",
      "Epoch 24, Loss: 0.4791439872404391, Validation Accuracy: 78.46%\n",
      "Epoch 25, Loss: 0.47556812451644376, Validation Accuracy: 75.12%\n",
      "Epoch 26, Loss: 0.46609834530814126, Validation Accuracy: 81.7%\n",
      "Epoch 27, Loss: 0.4619971103966236, Validation Accuracy: 69.98%\n",
      "Epoch 28, Loss: 0.45852645207196474, Validation Accuracy: 80.42%\n",
      "Epoch 29, Loss: 0.4645160860805349, Validation Accuracy: 79.38%\n",
      "Epoch 30, Loss: 0.45509511875835335, Validation Accuracy: 79.92%\n",
      "Epoch 31, Loss: 0.45411573435095226, Validation Accuracy: 80.56%\n",
      "Epoch 32, Loss: 0.4480149194767529, Validation Accuracy: 77.18%\n",
      "Epoch 33, Loss: 0.44933721152218903, Validation Accuracy: 77.58%\n",
      "Epoch 34, Loss: 0.4434343889694322, Validation Accuracy: 79.1%\n",
      "Epoch 35, Loss: 0.441058256409385, Validation Accuracy: 80.56%\n",
      "Epoch 36, Loss: 0.44141503355719824, Validation Accuracy: 77.04%\n",
      "Epoch 37, Loss: 0.43748638592660427, Validation Accuracy: 82.38%\n",
      "Epoch 38, Loss: 0.4344487401487475, Validation Accuracy: 78.74%\n",
      "Epoch 39, Loss: 0.4228629170578312, Validation Accuracy: 81.02%\n",
      "Epoch 40, Loss: 0.42448701840740716, Validation Accuracy: 81.88%\n",
      "Epoch 41, Loss: 0.4269956767305054, Validation Accuracy: 80.78%\n",
      "Epoch 42, Loss: 0.4314944526095959, Validation Accuracy: 79.94%\n",
      "Epoch 43, Loss: 0.4282140688208694, Validation Accuracy: 79.4%\n",
      "Epoch 44, Loss: 0.4196758669039065, Validation Accuracy: 78.28%\n",
      "Epoch 45, Loss: 0.42122527973895724, Validation Accuracy: 80.68%\n",
      "Epoch 46, Loss: 0.4164957507852126, Validation Accuracy: 77.9%\n",
      "Epoch 47, Loss: 0.420467952393334, Validation Accuracy: 81.46%\n",
      "Epoch 48, Loss: 0.41782236272807827, Validation Accuracy: 78.94%\n",
      "Epoch 49, Loss: 0.40821810460395436, Validation Accuracy: 79.18%\n",
      "Epoch 50, Loss: 0.4037690140645612, Validation Accuracy: 79.9%\n",
      "Epoch 51, Loss: 0.4176862321116708, Validation Accuracy: 81.6%\n",
      "Epoch 52, Loss: 0.41078018028797075, Validation Accuracy: 80.08%\n",
      "Epoch 53, Loss: 0.4078217682174661, Validation Accuracy: 82.32%\n",
      "Epoch 54, Loss: 0.40460744622925465, Validation Accuracy: 77.1%\n",
      "Epoch 55, Loss: 0.40078977800228377, Validation Accuracy: 82.72%\n",
      "Epoch 56, Loss: 0.40192000788043847, Validation Accuracy: 78.38%\n",
      "Epoch 57, Loss: 0.3973822198723527, Validation Accuracy: 79.7%\n",
      "Epoch 58, Loss: 0.3956695843741975, Validation Accuracy: 81.86%\n",
      "Epoch 59, Loss: 0.3898172907277264, Validation Accuracy: 78.86%\n",
      "Epoch 60, Loss: 0.39213489736853674, Validation Accuracy: 84.3%\n",
      "Epoch 61, Loss: 0.384239973500371, Validation Accuracy: 83.98%\n",
      "Epoch 62, Loss: 0.38798804996027186, Validation Accuracy: 81.36%\n",
      "Epoch 63, Loss: 0.3848704500547187, Validation Accuracy: 81.28%\n",
      "Epoch 64, Loss: 0.3787925071929666, Validation Accuracy: 78.0%\n",
      "Epoch 65, Loss: 0.38889487786218524, Validation Accuracy: 82.64%\n",
      "Epoch 66, Loss: 0.3761599237861281, Validation Accuracy: 78.68%\n",
      "Epoch 67, Loss: 0.3751150621947917, Validation Accuracy: 81.6%\n",
      "Epoch 68, Loss: 0.37591936003247445, Validation Accuracy: 80.94%\n",
      "Epoch 69, Loss: 0.3721248328008435, Validation Accuracy: 82.08%\n",
      "Epoch 70, Loss: 0.3690639956515621, Validation Accuracy: 82.12%\n",
      "Epoch 71, Loss: 0.3656897957606072, Validation Accuracy: 82.18%\n",
      "Epoch 72, Loss: 0.36691361538727174, Validation Accuracy: 82.48%\n",
      "Epoch 73, Loss: 0.36442363588139415, Validation Accuracy: 82.0%\n",
      "Epoch 74, Loss: 0.3666286396116696, Validation Accuracy: 83.16%\n",
      "Epoch 75, Loss: 0.35891977714543993, Validation Accuracy: 81.22%\n",
      "Epoch 76, Loss: 0.3579958231103691, Validation Accuracy: 84.46%\n",
      "Epoch 77, Loss: 0.3520916612734171, Validation Accuracy: 82.44%\n",
      "Epoch 78, Loss: 0.35099447349255736, Validation Accuracy: 82.6%\n",
      "Epoch 79, Loss: 0.35396865306591446, Validation Accuracy: 80.84%\n",
      "Epoch 80, Loss: 0.3446992398239672, Validation Accuracy: 82.5%\n",
      "Epoch 81, Loss: 0.34588816165077413, Validation Accuracy: 81.64%\n",
      "Epoch 82, Loss: 0.3464585207826035, Validation Accuracy: 81.6%\n",
      "Epoch 83, Loss: 0.3373581458899108, Validation Accuracy: 83.08%\n",
      "Epoch 84, Loss: 0.3368102657524022, Validation Accuracy: 82.4%\n",
      "Epoch 85, Loss: 0.3386350814253092, Validation Accuracy: 81.34%\n",
      "Epoch 86, Loss: 0.3347893438132649, Validation Accuracy: 83.98%\n",
      "Epoch 87, Loss: 0.32810738432983105, Validation Accuracy: 85.82%\n",
      "Epoch 88, Loss: 0.3238300656984476, Validation Accuracy: 83.16%\n",
      "Epoch 89, Loss: 0.3286408838307993, Validation Accuracy: 81.94%\n",
      "Epoch 90, Loss: 0.32221821606667206, Validation Accuracy: 85.96%\n",
      "Epoch 91, Loss: 0.3252955024469305, Validation Accuracy: 85.0%\n",
      "Epoch 92, Loss: 0.3208229031667791, Validation Accuracy: 83.34%\n",
      "Epoch 93, Loss: 0.31288074659691617, Validation Accuracy: 83.6%\n",
      "Epoch 94, Loss: 0.31644213178449054, Validation Accuracy: 82.3%\n",
      "Epoch 95, Loss: 0.3106389309448952, Validation Accuracy: 85.3%\n",
      "Epoch 96, Loss: 0.30954572232440114, Validation Accuracy: 84.8%\n",
      "Epoch 97, Loss: 0.299295109485022, Validation Accuracy: 84.52%\n",
      "Epoch 98, Loss: 0.30855966541408136, Validation Accuracy: 83.72%\n",
      "Epoch 99, Loss: 0.29716546867381444, Validation Accuracy: 85.1%\n",
      "Epoch 100, Loss: 0.2974812921813943, Validation Accuracy: 84.02%\n",
      "Epoch 101, Loss: 0.29186055923558096, Validation Accuracy: 84.64%\n",
      "Epoch 102, Loss: 0.2918930489315905, Validation Accuracy: 83.42%\n",
      "Epoch 103, Loss: 0.2876065955920653, Validation Accuracy: 83.32%\n",
      "Epoch 104, Loss: 0.29116977247494186, Validation Accuracy: 85.92%\n",
      "Epoch 105, Loss: 0.2818434007296508, Validation Accuracy: 86.18%\n",
      "Epoch 106, Loss: 0.2802105334333398, Validation Accuracy: 86.56%\n",
      "Epoch 107, Loss: 0.2724920299581506, Validation Accuracy: 85.8%\n",
      "Epoch 108, Loss: 0.2757856825959276, Validation Accuracy: 84.84%\n",
      "Epoch 109, Loss: 0.26856230123137886, Validation Accuracy: 82.26%\n",
      "Epoch 110, Loss: 0.2689921337137507, Validation Accuracy: 85.54%\n",
      "Epoch 111, Loss: 0.262724472548474, Validation Accuracy: 85.64%\n",
      "Epoch 112, Loss: 0.2607859614813192, Validation Accuracy: 85.08%\n",
      "Epoch 113, Loss: 0.25654965164986526, Validation Accuracy: 86.8%\n",
      "Epoch 114, Loss: 0.25214515772478824, Validation Accuracy: 85.3%\n",
      "Epoch 115, Loss: 0.24981458207846366, Validation Accuracy: 87.12%\n",
      "Epoch 116, Loss: 0.24663804189979352, Validation Accuracy: 84.58%\n",
      "Epoch 117, Loss: 0.24834981865503572, Validation Accuracy: 85.68%\n",
      "Epoch 118, Loss: 0.23625333672812718, Validation Accuracy: 85.54%\n",
      "Epoch 119, Loss: 0.23849503101188352, Validation Accuracy: 83.56%\n",
      "Epoch 120, Loss: 0.23916101741435175, Validation Accuracy: 86.0%\n",
      "Epoch 121, Loss: 0.23232868269339882, Validation Accuracy: 86.02%\n",
      "Epoch 122, Loss: 0.2254913110412996, Validation Accuracy: 86.32%\n",
      "Epoch 123, Loss: 0.22862260236235504, Validation Accuracy: 85.46%\n",
      "Epoch 124, Loss: 0.2200927798509259, Validation Accuracy: 86.94%\n",
      "Epoch 125, Loss: 0.21544151003895837, Validation Accuracy: 86.74%\n",
      "Epoch 126, Loss: 0.21247096670876173, Validation Accuracy: 85.5%\n",
      "Epoch 127, Loss: 0.21517267372374507, Validation Accuracy: 87.86%\n",
      "Epoch 128, Loss: 0.2061231314543296, Validation Accuracy: 87.26%\n",
      "Epoch 129, Loss: 0.19980804992585696, Validation Accuracy: 85.3%\n",
      "Epoch 130, Loss: 0.20264484464529564, Validation Accuracy: 86.8%\n",
      "Epoch 131, Loss: 0.19946164318191056, Validation Accuracy: 85.7%\n",
      "Epoch 132, Loss: 0.19429980622689155, Validation Accuracy: 88.04%\n",
      "Epoch 133, Loss: 0.1900249928744002, Validation Accuracy: 87.84%\n",
      "Epoch 134, Loss: 0.17899027111178095, Validation Accuracy: 88.18%\n",
      "Epoch 135, Loss: 0.1851164081176235, Validation Accuracy: 87.22%\n",
      "Epoch 136, Loss: 0.1756067068993368, Validation Accuracy: 87.98%\n",
      "Epoch 137, Loss: 0.1766005410093137, Validation Accuracy: 88.06%\n",
      "Epoch 138, Loss: 0.16912940569983964, Validation Accuracy: 88.44%\n",
      "Epoch 139, Loss: 0.1671051105315035, Validation Accuracy: 88.98%\n",
      "Epoch 140, Loss: 0.15673801321959632, Validation Accuracy: 88.44%\n",
      "Epoch 141, Loss: 0.16051529892931946, Validation Accuracy: 86.0%\n",
      "Epoch 142, Loss: 0.15395565116143023, Validation Accuracy: 89.72%\n",
      "Epoch 143, Loss: 0.1497513137186285, Validation Accuracy: 89.1%\n",
      "Epoch 144, Loss: 0.14485421258194203, Validation Accuracy: 90.08%\n",
      "Epoch 145, Loss: 0.14134281405925073, Validation Accuracy: 89.26%\n",
      "Epoch 146, Loss: 0.1345773805991154, Validation Accuracy: 90.24%\n",
      "Epoch 147, Loss: 0.13195600840051405, Validation Accuracy: 89.26%\n",
      "Epoch 148, Loss: 0.13432995998300612, Validation Accuracy: 89.46%\n",
      "Epoch 149, Loss: 0.1280038186073811, Validation Accuracy: 89.9%\n",
      "Epoch 150, Loss: 0.11938900028524752, Validation Accuracy: 89.16%\n",
      "Epoch 151, Loss: 0.11441521480975841, Validation Accuracy: 88.9%\n",
      "Epoch 152, Loss: 0.10955778046892109, Validation Accuracy: 90.04%\n",
      "Epoch 153, Loss: 0.10674104703039947, Validation Accuracy: 90.68%\n",
      "Epoch 154, Loss: 0.10219744536814025, Validation Accuracy: 90.36%\n",
      "Epoch 155, Loss: 0.10442231707698242, Validation Accuracy: 90.72%\n",
      "Epoch 156, Loss: 0.09309368508084762, Validation Accuracy: 90.44%\n",
      "Epoch 157, Loss: 0.09220255577979102, Validation Accuracy: 90.14%\n",
      "Epoch 158, Loss: 0.088681142475583, Validation Accuracy: 90.32%\n",
      "Epoch 159, Loss: 0.07895697374425997, Validation Accuracy: 91.0%\n",
      "Epoch 160, Loss: 0.07549510964467614, Validation Accuracy: 90.12%\n",
      "Epoch 161, Loss: 0.07050144839343954, Validation Accuracy: 91.26%\n",
      "Epoch 162, Loss: 0.07480327089168978, Validation Accuracy: 90.62%\n",
      "Epoch 163, Loss: 0.06922010907543484, Validation Accuracy: 90.38%\n",
      "Epoch 164, Loss: 0.06383000290423463, Validation Accuracy: 90.4%\n",
      "Epoch 165, Loss: 0.061473428054755044, Validation Accuracy: 91.5%\n",
      "Epoch 166, Loss: 0.05502522446807812, Validation Accuracy: 91.08%\n",
      "Epoch 167, Loss: 0.053139496383003214, Validation Accuracy: 91.7%\n",
      "Epoch 168, Loss: 0.05011152403577315, Validation Accuracy: 91.14%\n",
      "Epoch 169, Loss: 0.048939535693286663, Validation Accuracy: 91.68%\n",
      "Epoch 170, Loss: 0.04512042055350982, Validation Accuracy: 91.8%\n",
      "Epoch 171, Loss: 0.04250494587838396, Validation Accuracy: 91.78%\n",
      "Epoch 172, Loss: 0.03929198515040546, Validation Accuracy: 91.96%\n",
      "Epoch 173, Loss: 0.0375014090386685, Validation Accuracy: 92.22%\n",
      "Epoch 174, Loss: 0.036349267766292374, Validation Accuracy: 92.44%\n",
      "Epoch 175, Loss: 0.03296107712693894, Validation Accuracy: 91.9%\n",
      "Epoch 176, Loss: 0.031817485581003974, Validation Accuracy: 92.18%\n",
      "Epoch 177, Loss: 0.02808947472592329, Validation Accuracy: 92.56%\n",
      "Epoch 178, Loss: 0.028266864437848035, Validation Accuracy: 92.5%\n",
      "Epoch 179, Loss: 0.025142145443665373, Validation Accuracy: 92.16%\n",
      "Epoch 180, Loss: 0.023361896190511867, Validation Accuracy: 92.4%\n",
      "Epoch 181, Loss: 0.021922675258379473, Validation Accuracy: 92.6%\n",
      "Epoch 182, Loss: 0.021690876145095735, Validation Accuracy: 92.54%\n",
      "Epoch 183, Loss: 0.0213274462459429, Validation Accuracy: 92.8%\n",
      "Epoch 184, Loss: 0.02061667769753099, Validation Accuracy: 92.5%\n",
      "Epoch 185, Loss: 0.020491466540658042, Validation Accuracy: 92.72%\n",
      "Epoch 186, Loss: 0.01945177462502298, Validation Accuracy: 93.04%\n",
      "Epoch 187, Loss: 0.018415191721446303, Validation Accuracy: 92.78%\n",
      "Epoch 188, Loss: 0.01798667076681423, Validation Accuracy: 92.98%\n",
      "Epoch 189, Loss: 0.01819348836645738, Validation Accuracy: 92.84%\n",
      "Epoch 190, Loss: 0.016262078564481766, Validation Accuracy: 93.0%\n",
      "Epoch 191, Loss: 0.016808229581907985, Validation Accuracy: 93.1%\n",
      "Epoch 192, Loss: 0.017555162560628643, Validation Accuracy: 93.18%\n",
      "Epoch 193, Loss: 0.01586987881786296, Validation Accuracy: 92.86%\n",
      "Epoch 194, Loss: 0.015694434476079714, Validation Accuracy: 93.08%\n",
      "Epoch 195, Loss: 0.01554658006220548, Validation Accuracy: 92.86%\n",
      "Epoch 196, Loss: 0.015002331459651363, Validation Accuracy: 93.18%\n",
      "Epoch 197, Loss: 0.01649521697518966, Validation Accuracy: 92.74%\n",
      "Epoch 198, Loss: 0.015723717522632796, Validation Accuracy: 93.0%\n",
      "Epoch 199, Loss: 0.01568704532970018, Validation Accuracy: 93.26%\n",
      "Epoch 200, Loss: 0.015353561386291403, Validation Accuracy: 93.2%\n",
      "Submission5 file saved.\n"
     ]
    }
   ],
   "source": [
    "# put models to devices (CPU/GPU)\n",
    "model = ResNetdl()\n",
    "\n",
    "# Two GPUs get double amount of parameters....???\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Print the number of parameters\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 32, 32))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=200) #change epoch\n",
    "\n",
    "# Generate submission file\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device) \n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('/kaggle/working/submission5.csv', index=False)\n",
    "print(\"Submission5 file saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5589.877376,
   "end_time": "2025-03-11T04:01:07.495725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T02:27:57.618349",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

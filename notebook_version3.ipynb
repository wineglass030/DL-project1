{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6c7cfe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-11T19:01:43.956752Z",
     "iopub.status.busy": "2025-03-11T19:01:43.956439Z",
     "iopub.status.idle": "2025-03-11T19:01:44.685775Z",
     "shell.execute_reply": "2025-03-11T19:01:44.684689Z"
    },
    "papermill": {
     "duration": 0.733792,
     "end_time": "2025-03-11T19:01:44.687616",
     "exception": false,
     "start_time": "2025-03-11T19:01:43.953824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4977ae9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:01:44.692064Z",
     "iopub.status.busy": "2025-03-11T19:01:44.691726Z",
     "iopub.status.idle": "2025-03-11T19:54:02.262768Z",
     "shell.execute_reply": "2025-03-11T19:54:02.261726Z"
    },
    "papermill": {
     "duration": 3137.574709,
     "end_time": "2025-03-11T19:54:02.264254",
     "exception": false,
     "start_time": "2025-03-11T19:01:44.689545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:03<00:00, 47.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,728\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
      "           Conv2d-12          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-14          [-1, 128, 16, 16]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "           Conv2d-17            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-18            [-1, 256, 8, 8]             512\n",
      "           Conv2d-19            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-20            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-21            [-1, 256, 8, 8]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-24            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-25            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-26            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-28            [-1, 512, 4, 4]               0\n",
      "           Linear-29                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,903,242\n",
      "Trainable params: 4,903,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.56\n",
      "Params size (MB): 18.70\n",
      "Estimated Total Size (MB): 25.28\n",
      "----------------------------------------------------------------\n",
      "Epoch 0, Loss: 1.576517, Training Accuracy: 41.66%\n",
      "Validation Loss: 1.267003, Validation Accuracy: 55.26%\n",
      "New Best Accuracy: 55.26% (Previous: 0.00%) - Saving Model...\n",
      "Epoch 1, Loss: 1.099856, Training Accuracy: 60.57%\n",
      "Validation Loss: 1.143590, Validation Accuracy: 59.43%\n",
      "New Best Accuracy: 59.43% (Previous: 55.26%) - Saving Model...\n",
      "Epoch 2, Loss: 0.900709, Training Accuracy: 68.08%\n",
      "Validation Loss: 0.913439, Validation Accuracy: 68.09%\n",
      "New Best Accuracy: 68.09% (Previous: 59.43%) - Saving Model...\n",
      "Epoch 3, Loss: 0.761461, Training Accuracy: 73.12%\n",
      "Validation Loss: 0.876115, Validation Accuracy: 69.78%\n",
      "New Best Accuracy: 69.78% (Previous: 68.09%) - Saving Model...\n",
      "Epoch 4, Loss: 0.653874, Training Accuracy: 77.15%\n",
      "Validation Loss: 0.886604, Validation Accuracy: 72.12%\n",
      "New Best Accuracy: 72.12% (Previous: 69.78%) - Saving Model...\n",
      "Epoch 5, Loss: 0.590708, Training Accuracy: 79.44%\n",
      "Validation Loss: 0.675778, Validation Accuracy: 77.54%\n",
      "New Best Accuracy: 77.54% (Previous: 72.12%) - Saving Model...\n",
      "Epoch 6, Loss: 0.549226, Training Accuracy: 80.93%\n",
      "Validation Loss: 0.712844, Validation Accuracy: 75.45%\n",
      "Epoch 7, Loss: 0.515173, Training Accuracy: 82.20%\n",
      "Validation Loss: 0.700368, Validation Accuracy: 77.35%\n",
      "Epoch 8, Loss: 0.487667, Training Accuracy: 83.37%\n",
      "Validation Loss: 0.812437, Validation Accuracy: 74.50%\n",
      "Epoch 9, Loss: 0.470634, Training Accuracy: 83.67%\n",
      "Validation Loss: 0.578835, Validation Accuracy: 79.94%\n",
      "New Best Accuracy: 79.94% (Previous: 77.54%) - Saving Model...\n",
      "Epoch 10, Loss: 0.459562, Training Accuracy: 84.16%\n",
      "Validation Loss: 1.038482, Validation Accuracy: 71.18%\n",
      "Epoch 11, Loss: 0.435161, Training Accuracy: 85.06%\n",
      "Validation Loss: 0.655700, Validation Accuracy: 78.46%\n",
      "Epoch 12, Loss: 0.431742, Training Accuracy: 85.10%\n",
      "Validation Loss: 0.649729, Validation Accuracy: 79.04%\n",
      "Epoch 13, Loss: 0.419767, Training Accuracy: 85.57%\n",
      "Validation Loss: 0.502024, Validation Accuracy: 83.25%\n",
      "New Best Accuracy: 83.25% (Previous: 79.94%) - Saving Model...\n",
      "Epoch 14, Loss: 0.414189, Training Accuracy: 85.77%\n",
      "Validation Loss: 0.590299, Validation Accuracy: 80.78%\n",
      "Epoch 15, Loss: 0.402052, Training Accuracy: 86.16%\n",
      "Validation Loss: 0.632541, Validation Accuracy: 79.01%\n",
      "Epoch 16, Loss: 0.395420, Training Accuracy: 86.40%\n",
      "Validation Loss: 0.549690, Validation Accuracy: 82.18%\n",
      "Epoch 17, Loss: 0.395389, Training Accuracy: 86.48%\n",
      "Validation Loss: 0.657240, Validation Accuracy: 78.93%\n",
      "Epoch 18, Loss: 0.389231, Training Accuracy: 86.79%\n",
      "Validation Loss: 0.486857, Validation Accuracy: 83.86%\n",
      "New Best Accuracy: 83.86% (Previous: 83.25%) - Saving Model...\n",
      "Epoch 19, Loss: 0.380278, Training Accuracy: 87.00%\n",
      "Validation Loss: 0.569371, Validation Accuracy: 81.31%\n",
      "Epoch 20, Loss: 0.378348, Training Accuracy: 87.07%\n",
      "Validation Loss: 0.590020, Validation Accuracy: 81.10%\n",
      "Epoch 21, Loss: 0.379981, Training Accuracy: 87.01%\n",
      "Validation Loss: 0.514401, Validation Accuracy: 82.61%\n",
      "Epoch 22, Loss: 0.367751, Training Accuracy: 87.46%\n",
      "Validation Loss: 0.558067, Validation Accuracy: 81.32%\n",
      "Epoch 23, Loss: 0.368348, Training Accuracy: 87.26%\n",
      "Validation Loss: 0.848489, Validation Accuracy: 74.40%\n",
      "Epoch 24, Loss: 0.365465, Training Accuracy: 87.54%\n",
      "Validation Loss: 0.651877, Validation Accuracy: 79.69%\n",
      "Epoch 25, Loss: 0.360646, Training Accuracy: 87.52%\n",
      "Validation Loss: 0.511561, Validation Accuracy: 82.81%\n",
      "Epoch 26, Loss: 0.362057, Training Accuracy: 87.58%\n",
      "Validation Loss: 0.656458, Validation Accuracy: 79.12%\n",
      "Epoch 27, Loss: 0.353148, Training Accuracy: 87.74%\n",
      "Validation Loss: 0.508362, Validation Accuracy: 83.84%\n",
      "Epoch 28, Loss: 0.351698, Training Accuracy: 87.76%\n",
      "Validation Loss: 0.472154, Validation Accuracy: 84.44%\n",
      "New Best Accuracy: 84.44% (Previous: 83.86%) - Saving Model...\n",
      "Epoch 29, Loss: 0.349284, Training Accuracy: 87.97%\n",
      "Validation Loss: 0.449060, Validation Accuracy: 85.28%\n",
      "New Best Accuracy: 85.28% (Previous: 84.44%) - Saving Model...\n",
      "Epoch 30, Loss: 0.354680, Training Accuracy: 87.78%\n",
      "Validation Loss: 0.566744, Validation Accuracy: 81.65%\n",
      "Epoch 31, Loss: 0.350337, Training Accuracy: 88.03%\n",
      "Validation Loss: 0.477357, Validation Accuracy: 84.29%\n",
      "Epoch 32, Loss: 0.350931, Training Accuracy: 87.96%\n",
      "Validation Loss: 0.486854, Validation Accuracy: 84.01%\n",
      "Epoch 33, Loss: 0.343296, Training Accuracy: 88.22%\n",
      "Validation Loss: 0.601085, Validation Accuracy: 81.51%\n",
      "Epoch 34, Loss: 0.340893, Training Accuracy: 88.25%\n",
      "Validation Loss: 0.483807, Validation Accuracy: 83.30%\n",
      "Epoch 35, Loss: 0.338975, Training Accuracy: 88.27%\n",
      "Validation Loss: 0.496449, Validation Accuracy: 83.00%\n",
      "Epoch 36, Loss: 0.343070, Training Accuracy: 88.18%\n",
      "Validation Loss: 0.665372, Validation Accuracy: 79.44%\n",
      "Epoch 37, Loss: 0.338077, Training Accuracy: 88.32%\n",
      "Validation Loss: 0.682077, Validation Accuracy: 78.89%\n",
      "Epoch 38, Loss: 0.337727, Training Accuracy: 88.44%\n",
      "Validation Loss: 0.494837, Validation Accuracy: 83.79%\n",
      "Epoch 39, Loss: 0.335445, Training Accuracy: 88.43%\n",
      "Validation Loss: 0.604141, Validation Accuracy: 80.61%\n",
      "Epoch 40, Loss: 0.329839, Training Accuracy: 88.74%\n",
      "Validation Loss: 0.860762, Validation Accuracy: 75.86%\n",
      "Epoch 41, Loss: 0.332462, Training Accuracy: 88.44%\n",
      "Validation Loss: 0.564075, Validation Accuracy: 82.23%\n",
      "Epoch 42, Loss: 0.328007, Training Accuracy: 88.69%\n",
      "Validation Loss: 0.641871, Validation Accuracy: 79.02%\n",
      "Epoch 43, Loss: 0.331150, Training Accuracy: 88.54%\n",
      "Validation Loss: 0.421990, Validation Accuracy: 86.05%\n",
      "New Best Accuracy: 86.05% (Previous: 85.28%) - Saving Model...\n",
      "Epoch 44, Loss: 0.323665, Training Accuracy: 88.87%\n",
      "Validation Loss: 0.442966, Validation Accuracy: 85.49%\n",
      "Epoch 45, Loss: 0.328656, Training Accuracy: 88.85%\n",
      "Validation Loss: 0.495331, Validation Accuracy: 83.62%\n",
      "Epoch 46, Loss: 0.323342, Training Accuracy: 88.95%\n",
      "Validation Loss: 0.403175, Validation Accuracy: 86.64%\n",
      "New Best Accuracy: 86.64% (Previous: 86.05%) - Saving Model...\n",
      "Epoch 47, Loss: 0.319522, Training Accuracy: 88.91%\n",
      "Validation Loss: 0.531682, Validation Accuracy: 82.53%\n",
      "Epoch 48, Loss: 0.319988, Training Accuracy: 89.10%\n",
      "Validation Loss: 0.493808, Validation Accuracy: 84.54%\n",
      "Epoch 49, Loss: 0.317316, Training Accuracy: 88.96%\n",
      "Validation Loss: 0.472683, Validation Accuracy: 84.43%\n",
      "Epoch 50, Loss: 0.320034, Training Accuracy: 89.01%\n",
      "Validation Loss: 0.516550, Validation Accuracy: 83.36%\n",
      "Epoch 51, Loss: 0.311939, Training Accuracy: 89.28%\n",
      "Validation Loss: 0.440068, Validation Accuracy: 85.75%\n",
      "Epoch 52, Loss: 0.315008, Training Accuracy: 89.24%\n",
      "Validation Loss: 0.416433, Validation Accuracy: 85.82%\n",
      "Epoch 53, Loss: 0.311681, Training Accuracy: 89.32%\n",
      "Validation Loss: 0.446724, Validation Accuracy: 84.94%\n",
      "Epoch 54, Loss: 0.306378, Training Accuracy: 89.45%\n",
      "Validation Loss: 0.537818, Validation Accuracy: 83.53%\n",
      "Epoch 55, Loss: 0.304694, Training Accuracy: 89.72%\n",
      "Validation Loss: 0.501237, Validation Accuracy: 83.57%\n",
      "Epoch 56, Loss: 0.304462, Training Accuracy: 89.39%\n",
      "Validation Loss: 0.470183, Validation Accuracy: 84.09%\n",
      "Epoch 57, Loss: 0.307722, Training Accuracy: 89.53%\n",
      "Validation Loss: 0.542251, Validation Accuracy: 82.43%\n",
      "Epoch 58, Loss: 0.299384, Training Accuracy: 89.64%\n",
      "Validation Loss: 0.471545, Validation Accuracy: 84.20%\n",
      "Epoch 59, Loss: 0.304861, Training Accuracy: 89.62%\n",
      "Validation Loss: 0.424426, Validation Accuracy: 85.64%\n",
      "Epoch 60, Loss: 0.300731, Training Accuracy: 89.61%\n",
      "Validation Loss: 0.390574, Validation Accuracy: 87.37%\n",
      "New Best Accuracy: 87.37% (Previous: 86.64%) - Saving Model...\n",
      "Epoch 61, Loss: 0.295684, Training Accuracy: 89.88%\n",
      "Validation Loss: 0.544774, Validation Accuracy: 82.49%\n",
      "Epoch 62, Loss: 0.298606, Training Accuracy: 89.75%\n",
      "Validation Loss: 0.478040, Validation Accuracy: 84.46%\n",
      "Epoch 63, Loss: 0.294376, Training Accuracy: 89.85%\n",
      "Validation Loss: 0.766982, Validation Accuracy: 77.56%\n",
      "Epoch 64, Loss: 0.290219, Training Accuracy: 90.05%\n",
      "Validation Loss: 0.374806, Validation Accuracy: 87.60%\n",
      "New Best Accuracy: 87.60% (Previous: 87.37%) - Saving Model...\n",
      "Epoch 65, Loss: 0.288596, Training Accuracy: 90.14%\n",
      "Validation Loss: 0.406064, Validation Accuracy: 85.99%\n",
      "Epoch 66, Loss: 0.284658, Training Accuracy: 90.23%\n",
      "Validation Loss: 0.380002, Validation Accuracy: 87.36%\n",
      "Epoch 67, Loss: 0.285003, Training Accuracy: 90.28%\n",
      "Validation Loss: 0.787576, Validation Accuracy: 76.46%\n",
      "Epoch 68, Loss: 0.287298, Training Accuracy: 90.03%\n",
      "Validation Loss: 0.522920, Validation Accuracy: 84.05%\n",
      "Epoch 69, Loss: 0.283186, Training Accuracy: 90.10%\n",
      "Validation Loss: 0.424707, Validation Accuracy: 86.08%\n",
      "Epoch 70, Loss: 0.280473, Training Accuracy: 90.25%\n",
      "Validation Loss: 0.550089, Validation Accuracy: 83.02%\n",
      "Epoch 71, Loss: 0.278207, Training Accuracy: 90.32%\n",
      "Validation Loss: 0.462664, Validation Accuracy: 85.55%\n",
      "Epoch 72, Loss: 0.279247, Training Accuracy: 90.41%\n",
      "Validation Loss: 0.451963, Validation Accuracy: 85.40%\n",
      "Epoch 73, Loss: 0.274988, Training Accuracy: 90.48%\n",
      "Validation Loss: 0.444830, Validation Accuracy: 85.48%\n",
      "Epoch 74, Loss: 0.268827, Training Accuracy: 90.79%\n",
      "Validation Loss: 0.646644, Validation Accuracy: 80.56%\n",
      "Epoch 75, Loss: 0.270895, Training Accuracy: 90.66%\n",
      "Validation Loss: 0.582959, Validation Accuracy: 81.70%\n",
      "Epoch 76, Loss: 0.268859, Training Accuracy: 90.57%\n",
      "Validation Loss: 0.490706, Validation Accuracy: 84.29%\n",
      "Epoch 77, Loss: 0.264554, Training Accuracy: 90.92%\n",
      "Validation Loss: 0.462722, Validation Accuracy: 85.78%\n",
      "Epoch 78, Loss: 0.262638, Training Accuracy: 91.03%\n",
      "Validation Loss: 0.424452, Validation Accuracy: 86.50%\n",
      "Epoch 79, Loss: 0.263126, Training Accuracy: 90.95%\n",
      "Validation Loss: 0.486036, Validation Accuracy: 85.03%\n",
      "Epoch 80, Loss: 0.262223, Training Accuracy: 91.07%\n",
      "Validation Loss: 0.472641, Validation Accuracy: 85.45%\n",
      "Epoch 81, Loss: 0.253342, Training Accuracy: 91.30%\n",
      "Validation Loss: 0.516869, Validation Accuracy: 83.66%\n",
      "Epoch 82, Loss: 0.264471, Training Accuracy: 90.89%\n",
      "Validation Loss: 0.471569, Validation Accuracy: 85.06%\n",
      "Epoch 83, Loss: 0.250785, Training Accuracy: 91.43%\n",
      "Validation Loss: 0.432449, Validation Accuracy: 86.06%\n",
      "Epoch 84, Loss: 0.248470, Training Accuracy: 91.55%\n",
      "Validation Loss: 0.451795, Validation Accuracy: 85.67%\n",
      "Epoch 85, Loss: 0.254851, Training Accuracy: 91.19%\n",
      "Validation Loss: 0.469510, Validation Accuracy: 85.24%\n",
      "Epoch 86, Loss: 0.245818, Training Accuracy: 91.57%\n",
      "Validation Loss: 0.408210, Validation Accuracy: 86.57%\n",
      "Epoch 87, Loss: 0.238757, Training Accuracy: 91.77%\n",
      "Validation Loss: 0.555569, Validation Accuracy: 83.35%\n",
      "Epoch 88, Loss: 0.245767, Training Accuracy: 91.46%\n",
      "Validation Loss: 0.456864, Validation Accuracy: 85.16%\n",
      "Epoch 89, Loss: 0.234617, Training Accuracy: 91.96%\n",
      "Validation Loss: 0.650737, Validation Accuracy: 81.28%\n",
      "Epoch 90, Loss: 0.239957, Training Accuracy: 91.68%\n",
      "Validation Loss: 0.491239, Validation Accuracy: 85.28%\n",
      "Epoch 91, Loss: 0.233794, Training Accuracy: 91.91%\n",
      "Validation Loss: 0.459492, Validation Accuracy: 85.99%\n",
      "Epoch 92, Loss: 0.236569, Training Accuracy: 91.83%\n",
      "Validation Loss: 0.506535, Validation Accuracy: 84.05%\n",
      "Epoch 93, Loss: 0.228613, Training Accuracy: 92.17%\n",
      "Validation Loss: 0.394075, Validation Accuracy: 87.37%\n",
      "Epoch 94, Loss: 0.229012, Training Accuracy: 92.00%\n",
      "Validation Loss: 0.467845, Validation Accuracy: 85.55%\n",
      "Epoch 95, Loss: 0.223991, Training Accuracy: 92.31%\n",
      "Validation Loss: 0.540411, Validation Accuracy: 84.24%\n",
      "Epoch 96, Loss: 0.228698, Training Accuracy: 92.14%\n",
      "Validation Loss: 0.411847, Validation Accuracy: 87.45%\n",
      "Epoch 97, Loss: 0.221319, Training Accuracy: 92.39%\n",
      "Validation Loss: 0.395944, Validation Accuracy: 86.89%\n",
      "Epoch 98, Loss: 0.219067, Training Accuracy: 92.38%\n",
      "Validation Loss: 0.392610, Validation Accuracy: 87.56%\n",
      "Epoch 99, Loss: 0.218433, Training Accuracy: 92.45%\n",
      "Validation Loss: 0.457307, Validation Accuracy: 85.55%\n",
      "Epoch 100, Loss: 0.209609, Training Accuracy: 92.78%\n",
      "Validation Loss: 0.413445, Validation Accuracy: 87.32%\n",
      "Epoch 101, Loss: 0.212075, Training Accuracy: 92.73%\n",
      "Validation Loss: 0.360765, Validation Accuracy: 88.70%\n",
      "New Best Accuracy: 88.70% (Previous: 87.60%) - Saving Model...\n",
      "Epoch 102, Loss: 0.204203, Training Accuracy: 92.88%\n",
      "Validation Loss: 0.351615, Validation Accuracy: 88.69%\n",
      "Epoch 103, Loss: 0.202684, Training Accuracy: 93.00%\n",
      "Validation Loss: 0.369211, Validation Accuracy: 87.89%\n",
      "Epoch 104, Loss: 0.209690, Training Accuracy: 92.69%\n",
      "Validation Loss: 0.354682, Validation Accuracy: 88.81%\n",
      "New Best Accuracy: 88.81% (Previous: 88.70%) - Saving Model...\n",
      "Epoch 105, Loss: 0.199330, Training Accuracy: 93.15%\n",
      "Validation Loss: 0.378912, Validation Accuracy: 87.84%\n",
      "Epoch 106, Loss: 0.196873, Training Accuracy: 93.28%\n",
      "Validation Loss: 0.479682, Validation Accuracy: 85.88%\n",
      "Epoch 107, Loss: 0.190615, Training Accuracy: 93.48%\n",
      "Validation Loss: 0.415998, Validation Accuracy: 87.05%\n",
      "Epoch 108, Loss: 0.186538, Training Accuracy: 93.51%\n",
      "Validation Loss: 0.342039, Validation Accuracy: 89.37%\n",
      "New Best Accuracy: 89.37% (Previous: 88.81%) - Saving Model...\n",
      "Epoch 109, Loss: 0.187151, Training Accuracy: 93.45%\n",
      "Validation Loss: 0.460874, Validation Accuracy: 85.94%\n",
      "Epoch 110, Loss: 0.182676, Training Accuracy: 93.68%\n",
      "Validation Loss: 0.318673, Validation Accuracy: 89.58%\n",
      "New Best Accuracy: 89.58% (Previous: 89.37%) - Saving Model...\n",
      "Epoch 111, Loss: 0.183465, Training Accuracy: 93.68%\n",
      "Validation Loss: 0.356850, Validation Accuracy: 88.91%\n",
      "Epoch 112, Loss: 0.183909, Training Accuracy: 93.59%\n",
      "Validation Loss: 0.393537, Validation Accuracy: 87.64%\n",
      "Epoch 113, Loss: 0.173499, Training Accuracy: 94.02%\n",
      "Validation Loss: 0.312714, Validation Accuracy: 89.77%\n",
      "New Best Accuracy: 89.77% (Previous: 89.58%) - Saving Model...\n",
      "Epoch 114, Loss: 0.172039, Training Accuracy: 94.00%\n",
      "Validation Loss: 0.336996, Validation Accuracy: 89.11%\n",
      "Epoch 115, Loss: 0.170890, Training Accuracy: 94.14%\n",
      "Validation Loss: 0.431369, Validation Accuracy: 86.96%\n",
      "Epoch 116, Loss: 0.169061, Training Accuracy: 94.12%\n",
      "Validation Loss: 0.314814, Validation Accuracy: 90.05%\n",
      "New Best Accuracy: 90.05% (Previous: 89.77%) - Saving Model...\n",
      "Epoch 117, Loss: 0.164713, Training Accuracy: 94.35%\n",
      "Validation Loss: 0.327898, Validation Accuracy: 89.99%\n",
      "Epoch 118, Loss: 0.159382, Training Accuracy: 94.58%\n",
      "Validation Loss: 0.368045, Validation Accuracy: 88.81%\n",
      "Epoch 119, Loss: 0.158831, Training Accuracy: 94.45%\n",
      "Validation Loss: 0.475664, Validation Accuracy: 85.79%\n",
      "Epoch 120, Loss: 0.161496, Training Accuracy: 94.33%\n",
      "Validation Loss: 0.379670, Validation Accuracy: 88.55%\n",
      "Epoch 121, Loss: 0.156510, Training Accuracy: 94.60%\n",
      "Validation Loss: 0.286611, Validation Accuracy: 90.98%\n",
      "New Best Accuracy: 90.98% (Previous: 90.05%) - Saving Model...\n",
      "Epoch 122, Loss: 0.147731, Training Accuracy: 94.99%\n",
      "Validation Loss: 0.358380, Validation Accuracy: 88.93%\n",
      "Epoch 123, Loss: 0.144396, Training Accuracy: 95.01%\n",
      "Validation Loss: 0.366746, Validation Accuracy: 88.83%\n",
      "Epoch 124, Loss: 0.147390, Training Accuracy: 94.86%\n",
      "Validation Loss: 0.327819, Validation Accuracy: 89.71%\n",
      "Epoch 125, Loss: 0.138103, Training Accuracy: 95.23%\n",
      "Validation Loss: 0.444191, Validation Accuracy: 86.83%\n",
      "Epoch 126, Loss: 0.139099, Training Accuracy: 95.17%\n",
      "Validation Loss: 0.340250, Validation Accuracy: 89.58%\n",
      "Epoch 127, Loss: 0.133729, Training Accuracy: 95.45%\n",
      "Validation Loss: 0.336566, Validation Accuracy: 89.23%\n",
      "Epoch 128, Loss: 0.123883, Training Accuracy: 95.85%\n",
      "Validation Loss: 0.342642, Validation Accuracy: 89.78%\n",
      "Epoch 129, Loss: 0.128534, Training Accuracy: 95.68%\n",
      "Validation Loss: 0.369653, Validation Accuracy: 89.45%\n",
      "Epoch 130, Loss: 0.121169, Training Accuracy: 95.91%\n",
      "Validation Loss: 0.334632, Validation Accuracy: 90.01%\n",
      "Epoch 131, Loss: 0.122577, Training Accuracy: 95.79%\n",
      "Validation Loss: 0.348408, Validation Accuracy: 89.51%\n",
      "Epoch 132, Loss: 0.116619, Training Accuracy: 95.96%\n",
      "Validation Loss: 0.363314, Validation Accuracy: 88.99%\n",
      "Epoch 133, Loss: 0.115883, Training Accuracy: 96.04%\n",
      "Validation Loss: 0.379812, Validation Accuracy: 88.57%\n",
      "Epoch 134, Loss: 0.107086, Training Accuracy: 96.31%\n",
      "Validation Loss: 0.345259, Validation Accuracy: 89.59%\n",
      "Epoch 135, Loss: 0.106576, Training Accuracy: 96.32%\n",
      "Validation Loss: 0.355871, Validation Accuracy: 89.34%\n",
      "Epoch 136, Loss: 0.109369, Training Accuracy: 96.32%\n",
      "Validation Loss: 0.408354, Validation Accuracy: 88.66%\n",
      "Epoch 137, Loss: 0.100794, Training Accuracy: 96.62%\n",
      "Validation Loss: 0.378629, Validation Accuracy: 88.97%\n",
      "Epoch 138, Loss: 0.099003, Training Accuracy: 96.64%\n",
      "Validation Loss: 0.334886, Validation Accuracy: 89.89%\n",
      "Epoch 139, Loss: 0.093798, Training Accuracy: 96.84%\n",
      "Validation Loss: 0.357434, Validation Accuracy: 89.61%\n",
      "Epoch 140, Loss: 0.090495, Training Accuracy: 96.95%\n",
      "Validation Loss: 0.346747, Validation Accuracy: 90.33%\n",
      "Epoch 141, Loss: 0.083815, Training Accuracy: 97.19%\n",
      "Validation Loss: 0.293422, Validation Accuracy: 91.52%\n",
      "New Best Accuracy: 91.52% (Previous: 90.98%) - Saving Model...\n",
      "Epoch 142, Loss: 0.085043, Training Accuracy: 97.10%\n",
      "Validation Loss: 0.317409, Validation Accuracy: 90.65%\n",
      "Epoch 143, Loss: 0.072833, Training Accuracy: 97.60%\n",
      "Validation Loss: 0.306037, Validation Accuracy: 90.85%\n",
      "Epoch 144, Loss: 0.077434, Training Accuracy: 97.40%\n",
      "Validation Loss: 0.273658, Validation Accuracy: 91.63%\n",
      "New Best Accuracy: 91.63% (Previous: 91.52%) - Saving Model...\n",
      "Epoch 145, Loss: 0.074163, Training Accuracy: 97.56%\n",
      "Validation Loss: 0.307069, Validation Accuracy: 91.06%\n",
      "Epoch 146, Loss: 0.066751, Training Accuracy: 97.83%\n",
      "Validation Loss: 0.310957, Validation Accuracy: 91.17%\n",
      "Epoch 147, Loss: 0.063416, Training Accuracy: 97.90%\n",
      "Validation Loss: 0.300025, Validation Accuracy: 91.38%\n",
      "Epoch 148, Loss: 0.063378, Training Accuracy: 97.99%\n",
      "Validation Loss: 0.308863, Validation Accuracy: 91.61%\n",
      "Epoch 149, Loss: 0.061076, Training Accuracy: 98.06%\n",
      "Validation Loss: 0.291447, Validation Accuracy: 91.72%\n",
      "New Best Accuracy: 91.72% (Previous: 91.63%) - Saving Model...\n",
      "Epoch 150, Loss: 0.057209, Training Accuracy: 98.16%\n",
      "Validation Loss: 0.289206, Validation Accuracy: 91.79%\n",
      "New Best Accuracy: 91.79% (Previous: 91.72%) - Saving Model...\n",
      "Epoch 151, Loss: 0.051560, Training Accuracy: 98.39%\n",
      "Validation Loss: 0.321826, Validation Accuracy: 90.97%\n",
      "Epoch 152, Loss: 0.049639, Training Accuracy: 98.42%\n",
      "Validation Loss: 0.307411, Validation Accuracy: 91.42%\n",
      "Epoch 153, Loss: 0.046419, Training Accuracy: 98.57%\n",
      "Validation Loss: 0.274630, Validation Accuracy: 92.18%\n",
      "New Best Accuracy: 92.18% (Previous: 91.79%) - Saving Model...\n",
      "Epoch 154, Loss: 0.042346, Training Accuracy: 98.67%\n",
      "Validation Loss: 0.262174, Validation Accuracy: 92.04%\n",
      "Epoch 155, Loss: 0.036306, Training Accuracy: 98.91%\n",
      "Validation Loss: 0.271863, Validation Accuracy: 92.35%\n",
      "New Best Accuracy: 92.35% (Previous: 92.18%) - Saving Model...\n",
      "Epoch 156, Loss: 0.035667, Training Accuracy: 98.88%\n",
      "Validation Loss: 0.280573, Validation Accuracy: 92.61%\n",
      "New Best Accuracy: 92.61% (Previous: 92.35%) - Saving Model...\n",
      "Epoch 157, Loss: 0.033449, Training Accuracy: 99.01%\n",
      "Validation Loss: 0.261058, Validation Accuracy: 92.54%\n",
      "Epoch 158, Loss: 0.028185, Training Accuracy: 99.20%\n",
      "Validation Loss: 0.237889, Validation Accuracy: 93.33%\n",
      "New Best Accuracy: 93.33% (Previous: 92.61%) - Saving Model...\n",
      "Epoch 159, Loss: 0.021795, Training Accuracy: 99.48%\n",
      "Validation Loss: 0.230682, Validation Accuracy: 93.53%\n",
      "New Best Accuracy: 93.53% (Previous: 93.33%) - Saving Model...\n",
      "Epoch 160, Loss: 0.021431, Training Accuracy: 99.48%\n",
      "Validation Loss: 0.251533, Validation Accuracy: 93.10%\n",
      "Epoch 161, Loss: 0.018098, Training Accuracy: 99.58%\n",
      "Validation Loss: 0.243575, Validation Accuracy: 93.28%\n",
      "Epoch 162, Loss: 0.017748, Training Accuracy: 99.59%\n",
      "Validation Loss: 0.238789, Validation Accuracy: 93.48%\n",
      "Epoch 163, Loss: 0.016150, Training Accuracy: 99.62%\n",
      "Validation Loss: 0.236360, Validation Accuracy: 93.29%\n",
      "Epoch 164, Loss: 0.012670, Training Accuracy: 99.78%\n",
      "Validation Loss: 0.230681, Validation Accuracy: 93.60%\n",
      "New Best Accuracy: 93.60% (Previous: 93.53%) - Saving Model...\n",
      "Epoch 165, Loss: 0.010797, Training Accuracy: 99.80%\n",
      "Validation Loss: 0.235265, Validation Accuracy: 93.62%\n",
      "New Best Accuracy: 93.62% (Previous: 93.60%) - Saving Model...\n",
      "Epoch 166, Loss: 0.009737, Training Accuracy: 99.84%\n",
      "Validation Loss: 0.218925, Validation Accuracy: 93.65%\n",
      "New Best Accuracy: 93.65% (Previous: 93.62%) - Saving Model...\n",
      "Epoch 167, Loss: 0.008358, Training Accuracy: 99.88%\n",
      "Validation Loss: 0.217128, Validation Accuracy: 93.95%\n",
      "New Best Accuracy: 93.95% (Previous: 93.65%) - Saving Model...\n",
      "Epoch 168, Loss: 0.007836, Training Accuracy: 99.90%\n",
      "Validation Loss: 0.209538, Validation Accuracy: 94.12%\n",
      "New Best Accuracy: 94.12% (Previous: 93.95%) - Saving Model...\n",
      "Epoch 169, Loss: 0.007037, Training Accuracy: 99.91%\n",
      "Validation Loss: 0.209038, Validation Accuracy: 94.09%\n",
      "Epoch 170, Loss: 0.006294, Training Accuracy: 99.95%\n",
      "Validation Loss: 0.209304, Validation Accuracy: 94.12%\n",
      "Epoch 171, Loss: 0.005900, Training Accuracy: 99.96%\n",
      "Validation Loss: 0.208014, Validation Accuracy: 94.11%\n",
      "Epoch 172, Loss: 0.005527, Training Accuracy: 99.96%\n",
      "Validation Loss: 0.201716, Validation Accuracy: 94.23%\n",
      "New Best Accuracy: 94.23% (Previous: 94.12%) - Saving Model...\n",
      "Epoch 173, Loss: 0.005217, Training Accuracy: 99.96%\n",
      "Validation Loss: 0.206343, Validation Accuracy: 94.11%\n",
      "Epoch 174, Loss: 0.004954, Training Accuracy: 99.96%\n",
      "Validation Loss: 0.202799, Validation Accuracy: 94.16%\n",
      "Epoch 175, Loss: 0.004948, Training Accuracy: 99.96%\n",
      "Validation Loss: 0.201212, Validation Accuracy: 94.19%\n",
      "Epoch 176, Loss: 0.004489, Training Accuracy: 99.97%\n",
      "Validation Loss: 0.203186, Validation Accuracy: 94.15%\n",
      "Epoch 177, Loss: 0.004469, Training Accuracy: 99.97%\n",
      "Validation Loss: 0.204627, Validation Accuracy: 94.16%\n",
      "Epoch 178, Loss: 0.004302, Training Accuracy: 99.98%\n",
      "Validation Loss: 0.200612, Validation Accuracy: 94.22%\n",
      "Epoch 179, Loss: 0.004190, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.206910, Validation Accuracy: 94.24%\n",
      "New Best Accuracy: 94.24% (Previous: 94.23%) - Saving Model...\n",
      "Epoch 180, Loss: 0.004174, Training Accuracy: 99.98%\n",
      "Validation Loss: 0.200427, Validation Accuracy: 94.26%\n",
      "New Best Accuracy: 94.26% (Previous: 94.24%) - Saving Model...\n",
      "Epoch 181, Loss: 0.003937, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.198259, Validation Accuracy: 94.29%\n",
      "New Best Accuracy: 94.29% (Previous: 94.26%) - Saving Model...\n",
      "Epoch 182, Loss: 0.003981, Training Accuracy: 99.98%\n",
      "Validation Loss: 0.196899, Validation Accuracy: 94.22%\n",
      "Epoch 183, Loss: 0.003936, Training Accuracy: 99.98%\n",
      "Validation Loss: 0.197219, Validation Accuracy: 94.25%\n",
      "Epoch 184, Loss: 0.003768, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.196519, Validation Accuracy: 94.25%\n",
      "Epoch 185, Loss: 0.003685, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.198203, Validation Accuracy: 94.26%\n",
      "Epoch 186, Loss: 0.003693, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.196298, Validation Accuracy: 94.31%\n",
      "New Best Accuracy: 94.31% (Previous: 94.29%) - Saving Model...\n",
      "Epoch 187, Loss: 0.003652, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.197656, Validation Accuracy: 94.23%\n",
      "Epoch 188, Loss: 0.003730, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.196834, Validation Accuracy: 94.36%\n",
      "New Best Accuracy: 94.36% (Previous: 94.31%) - Saving Model...\n",
      "Epoch 189, Loss: 0.003495, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.196959, Validation Accuracy: 94.25%\n",
      "Epoch 190, Loss: 0.003585, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.197224, Validation Accuracy: 94.33%\n",
      "Epoch 191, Loss: 0.003726, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.194794, Validation Accuracy: 94.33%\n",
      "Epoch 192, Loss: 0.003416, Training Accuracy: 100.00%\n",
      "Validation Loss: 0.194101, Validation Accuracy: 94.35%\n",
      "Epoch 193, Loss: 0.003526, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.194625, Validation Accuracy: 94.36%\n",
      "Epoch 194, Loss: 0.003388, Training Accuracy: 100.00%\n",
      "Validation Loss: 0.195717, Validation Accuracy: 94.30%\n",
      "Epoch 195, Loss: 0.003684, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.195301, Validation Accuracy: 94.28%\n",
      "Epoch 196, Loss: 0.003437, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.194862, Validation Accuracy: 94.31%\n",
      "Epoch 197, Loss: 0.003508, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.194781, Validation Accuracy: 94.36%\n",
      "Epoch 198, Loss: 0.003518, Training Accuracy: 99.99%\n",
      "Validation Loss: 0.195460, Validation Accuracy: 94.40%\n",
      "New Best Accuracy: 94.40% (Previous: 94.36%) - Saving Model...\n",
      "Epoch 199, Loss: 0.003503, Training Accuracy: 100.00%\n",
      "Validation Loss: 0.195389, Validation Accuracy: 94.35%\n",
      "Submission5 file saved.\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Argument Parsing\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "args = parser.parse_args(args=[]) if 'ipykernel' in sys.modules else parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # Best test accuracy\n",
    "start_epoch = 0  # Start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "#  Define progress bar function\n",
    "def progress_bar(current, total, msg=\"\"):\n",
    "    bar = tqdm(total=total, position=0, leave=True)\n",
    "    bar.update(current)\n",
    "    bar.set_description(msg)\n",
    "\n",
    "# Data Preparation\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        return self.linear(out.view(out.size(0), -1))\n",
    "\n",
    "net = ResNet(BasicBlock, [1, 1, 1, 1]).to(device)\n",
    "summary(net, (3, 32, 32))\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "#  Training Function (Logs Loss & Accuracy)\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(trainloader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "    print(f\"Epoch {epoch}, Loss: {avg_loss:.6f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    return avg_loss\n",
    "\n",
    "#  Testing Function (Logs Validation Accuracy)\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_val_loss = total_loss / len(testloader)\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        print(f\"New Best Accuracy: {acc:.2f}% (Previous: {best_acc:.2f}%) - Saving Model...\")\n",
    "        best_acc = acc\n",
    "        os.makedirs('checkpoint', exist_ok=True)\n",
    "        torch.save({'net': net.state_dict(), 'acc': acc, 'epoch': epoch}, './checkpoint/ckpt.pth')\n",
    "\n",
    "    return avg_val_loss, acc, predictions\n",
    "\n",
    "#  Training Loop\n",
    "for epoch in range(start_epoch, start_epoch + 200):\n",
    "    train_loss = train(epoch)\n",
    "    val_loss, val_acc, predictions = test(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('/kaggle/working/submission5.csv', index=False)\n",
    "print(\"Submission5 file saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3142.691404,
   "end_time": "2025-03-11T19:54:04.009841",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T19:01:41.318437",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
